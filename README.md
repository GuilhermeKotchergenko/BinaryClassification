# BinaryClassification â€“ Tackling Imbalanced Binary Datasets from Scratch

> **Machine Learning I (CC2008) â€“ University of Porto**
> Academic YearÂ 2024/25Â Â· GuilhermeÂ KotchergenkoÂ Batista & YanÂ Coelho

---

## ðŸš€ Project at a Glance

|                 | Details                                                                                                                        |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| **Goal**        | Build and evaluate a **binary classifier implemented 100Â % in pure Python** (no `scikitâ€‘learn`) and make it *imbalanceâ€‘aware*. |
| **Datasets**    | 50 public benchmark datasets with imbalanced classes                                                                   |
| **Metrics**     | Accuracy, Balanced Accuracy, Precision, Recall, Fâ€‘score, ROCâ€‘AUC, Gâ€‘mean                                                              |
| **Outcome**     | Outcome â€“ Weighted New Sigmoid improves minority-class recall by +23 pp (0.69 â†’ 0.85) and balanced-accuracy by +9 pp (0.71 â†’ 0.80) while keeping F1 unchanged. Gains are significant (paired t, p < 0.001 for balanced-acc).                                                   |
| **Inspiration** | [rushter/MLAlgorithms](https://github.com/rushter/MLAlgorithms) for Logistic Regression logic.            |

---

## ðŸ“‚ Repository Layout

```
BinaryClassification/
â”œâ”€â”€ data/                      # Raw datasets
â”‚   â””â”€â”€ class_imbalance/
â”œâ”€â”€ notebooks/                 # Jupyter notebooks â€“ exploration & experiment tracking
â”‚   â”œâ”€â”€ 01_test_models.ipynb   # Quick tests
â”‚   â””â”€â”€ 02_global_execution.ipynb # Run every dataset â†’ aggregate global metrics
â”œâ”€â”€ src/                       # Pure-Python logistic-regression variants (baseline & imbalance-aware)
â”‚   â”œâ”€â”€ BCE_Logistic_Regression.py
â”‚   â”œâ”€â”€ BCE_NewSigmoid_Logistic_Regression.py
â”‚   â”œâ”€â”€ Focal_Loss_Logistic_Regression.py
â”‚   â”œâ”€â”€ Focal_Loss_DynamicAlpha_Logistic_Regression.py
â”‚   â”œâ”€â”€ Weighted_BCE_Logistic_Regression.py
â”‚   â””â”€â”€ Weighted_BCE_NewSigmoid_Logistic_Regression.py
â”œâ”€â”€ requirements.txt           # Reproducible Python env (tested on â‰¥ 3.10)
â”œâ”€â”€ README.md                  # â† you are here
â””â”€â”€ PracticalAssignment_ML1.pdf# Assignment brief (PDF)

```
---

## ðŸ QuickÂ Start

```bash
# 1) Clone
$ git clone https://github.com/GuilhermeKotchergenko/BinaryClassification.git
$ cd BinaryClassification

# 2) Set up an isolated environment (recommended)
$ python3 -m venv .venv && source .venv/bin/activate  # Linux/macOS

# 3) Install requirements
$ pip install -r requirements.txt

# 4) Explore the experiments
$ jupyter lab notebooks/02_global_execution.ipynb
```

## ðŸ“ˆ Key Results

Values: Mean Â± sd

| Model                | accuracy          | balanced_accuracy   | precision         | recall            | f1                | auc               | gmean             |
|:---------------------|:------------------|:--------------------|:------------------|:------------------|:------------------|:------------------|:------------------|
| BCE                  | 0.929 Â± 0.056 | 0.709 Â± 0.183           | 0.734 Â± 0.307     | 0.688 Â± 0.375     | 0.688 Â± 0.341     | 0.874 Â± 0.139     | 0.531 Â± 0.376     |
| BCE New Sigmoid      | 0.925 Â± 0.070     | 0.742 Â± 0.199       | 0.702 Â± 0.351     | 0.725 Â± 0.373     | 0.700 Â± 0.361     | 0.861 Â± 0.163     | 0.579 Â± 0.399     |
| Focal                | 0.918 Â± 0.067     | 0.724 Â± 0.191       | 0.691 Â± 0.300     | 0.749 Â± 0.350     | 0.701 Â± 0.317     | 0.874 Â± 0.140     | 0.561 Â± 0.380     |
| Focal Dynamic Alpha  | 0.641 Â± 0.284     | 0.712 Â± 0.149       | 0.453 Â± 0.355     | **0.969 Â± 0.074** | 0.538 Â± 0.324     | 0.876 Â± 0.137     | 0.584 Â± 0.313     |
| Weighted             | 0.701 Â± 0.221     | 0.764 Â± 0.142       | 0.490 Â± 0.350     | 0.921 Â± 0.125     | 0.560 Â± 0.298     | 0.872 Â± 0.140     | 0.704 Â± 0.240     |
| Weighted_New_Sigmoid | 0.837 Â± 0.178     | **0.796 Â± 0.175**   | 0.651 Â± 0.341     | 0.837 Â± 0.214     | 0.690 Â± 0.302     | 0.865 Â± 0.152     | **0.760 Â± 0.234** |


Black bars in the slide deck illustrate the entries that achieves the highest (and statistically-significant) value (paired Wilcoxon, *p*Â <Â 0.05).


## ðŸ“œ Licence

This work is licensed under the **MIT License** â€“ see [`LICENSE`](LICENSE) for details.

---
